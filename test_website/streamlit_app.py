# -*- coding: utf-8 -*-
from __future__ import annotations
import time
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st


# =============== åŸºç¡€è®¾ç½® ===============
st.set_page_config(
    page_title="æ•°æ®èšåˆå¤„ç†ç½‘ç«™",
    layout="wide",
    initial_sidebar_state="expanded",
)

# é¡¶éƒ¨+ä¸¤ä¾§æµ…è‰²æ¸å˜ + æ ‡é¢˜æ•´ä½“ä¸‹ç§» 75px
st.markdown(
    """
    <style>
      /* æ•´ä½“èƒŒæ™¯ç”±ä¸Šåˆ°ä¸‹æµ…è“æ¸å˜ */
      .stApp {
        background: linear-gradient(180deg, #e9f3ff 0%, #f7fbff 100%);
      }
      /* æ ‡é¢˜åŒºæ•´ä½“ä¸‹ç§» */
      .main .block-container{
        padding-top: 75px !important;
      }
      /* ä¸¤ä¾§ç«–å‘æ¸å˜æ¡ï¼ˆä¸å å†…å®¹ç©ºé—´ï¼‰ */
      body::before, body::after {
        content: "";
        position: fixed;
        top: 0; bottom: 0; width: 10px;
        pointer-events: none; z-index: 0;
      }
      body::before {
        left: 0;
        background: linear-gradient(#ffdf80, #70a1ff);
        opacity: .25;
      }
      body::after {
        right: 0;
        background: linear-gradient(#ffdf80, #70a1ff);
        opacity: .25;
      }
      /* è®©ä¾§è¾¹æ å§‹ç»ˆå¯è§æ›´é†’ç›®ï¼ˆå®½ä¸€ç‚¹ï¼‰ */
      [data-testid="stSidebar"] { width: 300px; min-width: 300px; }
    </style>
    """,
    unsafe_allow_html=True,
)

# æ•°æ®ä¿å­˜ç›®å½•
BASE_DIR   = Path(__file__).resolve().parent
UPLOAD_DIR = BASE_DIR / "uploads"
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)


# =============== å·¥å…·å‡½æ•° ===============
def list_saved_csvs(limit: int = 30) -> List[Path]:
    """åˆ—å‡ºå·²ä¿å­˜ CSVï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´å€’åºï¼‰"""
    files = list(UPLOAD_DIR.glob("*.csv"))
    files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return files[:limit]


def read_csv(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path)
    return df


def detect_numeric_cols(df: pd.DataFrame) -> List[str]:
    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]


def detect_time_cols(df: pd.DataFrame) -> List[str]:
    tcols = []
    for c in df.columns:
        try:
            pd.to_datetime(df[c], errors="raise")
            tcols.append(c)
        except Exception:
            pass
    return tcols


def human_size(num_bytes: int) -> str:
    """ç®€å•çš„äººç±»å¯è¯»å¤§å°"""
    units = ["B", "KB", "MB", "GB"]
    size = float(num_bytes)
    for u in units:
        if size < 1024.0:
            return f"{size:.1f}{u}"
        size /= 1024.0
    return f"{size:.1f}TB"


def save_and_activate(uploaded) -> None:
    """ä¿å­˜ä¸Šä¼ æ–‡ä»¶å¹¶ç«‹å³è®¾ä¸ºå½“å‰æ•°æ®é›†ï¼ˆè‡ªåŠ¨æ¿€æ´»ï¼‰"""
    import uuid
    fname = f"{Path(uploaded.name).stem}_{int(time.time())}_{uuid.uuid4().hex[:6]}.csv"
    save_path = UPLOAD_DIR / fname
    with open(save_path, "wb") as f:
        f.write(uploaded.getbuffer())

    df = read_csv(save_path)
    st.session_state["current_file_path"] = str(save_path)
    st.session_state["df"] = df
    st.session_state["numeric_cols"] = detect_numeric_cols(df)
    st.session_state["time_cols"] = detect_time_cols(df)
    st.success(f"å·²ä¸Šä¼ å¹¶è½½å…¥ï¼š{uploaded.name}")


def open_saved_file(path: Path) -> None:
    """ä»â€œå·²ä¿å­˜â€æ‰“å¼€å¹¶æ¿€æ´»"""
    df = read_csv(path)
    st.session_state["current_file_path"] = str(path)
    st.session_state["df"] = df
    st.session_state["numeric_cols"] = detect_numeric_cols(df)
    st.session_state["time_cols"] = detect_time_cols(df)
    st.success(f"å·²è½½å…¥ï¼š{path.name}")


def aggregate(
    df: pd.DataFrame,
    x_col: str,
    y_cols: List[str],
    agg: str,
    time_derive: str,
) -> pd.DataFrame:
    """æŒ‰ x å’Œ y_cols åšèšåˆï¼›è‹¥ x æ˜¯æ—¶é—´åˆ—ï¼Œå¯æ´¾ç”Ÿå°æ—¶/æ—¥/å‘¨/æœˆ"""
    data = df.copy()

    # æ—¶é—´æ´¾ç”Ÿ
    if time_derive != "ä¸æ´¾ç”Ÿ":
        # è‹¥ä¸æ˜¯æ—¶é—´ç±»å‹å…ˆè½¬
        if not pd.api.types.is_datetime64_any_dtype(data[x_col]):
            data[x_col] = pd.to_datetime(data[x_col], errors="coerce")

        if time_derive == "å°æ—¶(0-23)":
            data["_X"] = data[x_col].dt.hour
        elif time_derive == "æ—¥(YYYY-MM-DD)":
            data["_X"] = data[x_col].dt.date
        elif time_derive == "å‘¨(1-53)":
            data["_X"] = data[x_col].dt.isocalendar().week.astype(int)
        elif time_derive == "æœˆ(YYYY-MM)":
            data["_X"] = data[x_col].dt.to_period("M").astype(str)
        else:
            data["_X"] = data[x_col]
    else:
        data["_X"] = data[x_col]

    # åªä¿ç•™ y_cols
    y_cols = [c for c in y_cols if c in data.columns]
    if not y_cols:
        return pd.DataFrame()

    grouped = data.groupby("_X")[y_cols].agg(agg).reset_index().rename(columns={"_X": "X"})
    return grouped


# =============== çŠ¶æ€åˆå§‹åŒ– ===============
for k, v in {
    "df": None,
    "current_file_path": "",
    "numeric_cols": [],
    "time_cols": [],
}.items():
    st.session_state.setdefault(k, v)


# =============== ä¸»ä½“ ===============
st.title("æ•°æ®èšåˆå¤„ç†ç½‘ç«™")
st.caption("ä¸Šä¼  CSV â†’ å·¦ä¾§é€‰æ‹© X/æ—¶é—´æ´¾ç”Ÿ/Y/èšåˆä¸èŒƒå›´ â†’ å³ä¾§å‡ºå›¾ä¸å¯¼å‡º")

# --- ä¸Šä¼  / å·²ä¿å­˜æ–‡ä»¶ï¼ˆä¸»åŒºåŸŸï¼‰ ---
with st.container(border=True):
    st.subheader("ä¸Šä¼  CSVï¼ˆåŸå§‹ç»†ç²’æˆ–å·²èšåˆå‡å¯ï¼‰", divider=True)
    up = st.file_uploader("Drag and drop file here", type=["csv"], label_visibility="collapsed")
    if up is not None:
        # ä¸Šä¼ å³è‡ªåŠ¨æ¿€æ´»
        save_and_activate(up)

# å·²ä¿å­˜åˆ—è¡¨
with st.container(border=True):
    st.subheader("å·²ä¿å­˜æ–‡ä»¶ï¼ˆæœ€è¿‘ï¼‰", divider=True)
    files = list_saved_csvs()
    if not files:
        st.info("æš‚æ— å·²ä¿å­˜æ–‡ä»¶ã€‚è¯·å…ˆä¸Šä¼ ã€‚")
    else:
        labels = [
            f"{p.name} Â· {human_size(p.stat().st_size)} Â· {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(p.stat().st_mtime))}"
            for p in files
        ]
        idx = st.selectbox("ä»åˆ—è¡¨é‡Œé€‰æ‹©å¹¶æ‰“å¼€ï¼š", range(len(files)), format_func=lambda i: labels[i], index=0)
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("æ‰“å¼€æ­¤æ–‡ä»¶", use_container_width=True):
                open_saved_file(files[idx])
        with col2:
            st.text_input("æ–‡ä»¶ç»å¯¹è·¯å¾„", str(files[idx]), disabled=True)


# --- ä¾§æ ï¼šç»´åº¦ä¸åº¦é‡ ---
st.sidebar.header("ç»´åº¦ä¸åº¦é‡")

has_df = st.session_state["df"] is not None
df = st.session_state["df"]

# x ç»´åº¦ï¼ˆæ‰€æœ‰åˆ—éƒ½å¯ä»¥é€‰ï¼›æ²¡æœ‰ df æ—¶ç¦ç”¨ï¼‰
all_cols = list(df.columns) if has_df else []
x_col = st.sidebar.selectbox(
    "æ¨ªåæ ‡ (X)",
    all_cols if has_df else ["è¯·å…ˆä¸Šä¼ /é€‰æ‹© CSV æ–‡ä»¶"],
    disabled=not has_df,
    index=0 if has_df else None,
)

# æ—¶é—´æ´¾ç”Ÿ
time_choices = ["ä¸æ´¾ç”Ÿ", "å°æ—¶(0-23)", "æ—¥(YYYY-MM-DD)", "å‘¨(1-53)", "æœˆ(YYYY-MM)"]
time_gran = st.sidebar.selectbox(
    "æ—¶é—´æ´¾ç”Ÿ",
    time_choices,
    disabled=not has_df or (has_df and x_col not in st.session_state["time_cols"] and time_choices),
    help="å½“ X ä¸ºæ—¶é—´åˆ—æ—¶ï¼Œå¯ä»¥æ´¾ç”Ÿå‡ºå°æ—¶/æ—¥/å‘¨/æœˆï¼›è‹¥ä¸æ˜¯æ—¶é—´åˆ—æœ¬é¡¹ä¼šç¦ç”¨ã€‚",
)

# y é€‰æ‹©ï¼ˆå¤šé€‰ï¼Œéœ€è¦æ•°å€¼åˆ—ï¼‰
y_cols = st.sidebar.multiselect(
    "çºµåæ ‡ (Yï¼Œå¯å¤šé€‰)",
    st.session_state["numeric_cols"] if has_df else [],
    max_selections=3,
    placeholder="è¯·é€‰æ‹© 1-3 ä¸ªæ•°å€¼åˆ—",
    disabled=not has_df,
)

agg = st.sidebar.selectbox(
    "èšåˆæ–¹å¼ï¼ˆå¯¹ Y åˆ—ï¼‰",
    ["sum", "mean", "max", "min", "count"],
    disabled=not has_df,
)

# å…ˆæé†’
if not has_df:
    st.info("ğŸ‘‰ è¯·å…ˆä¸Šä¼ /é€‰æ‹© CSV æ–‡ä»¶ã€‚")
else:
    st.success(f"å½“å‰æ•°æ®ï¼š{Path(st.session_state['current_file_path']).name} Â· è¡Œæ•° {len(df):,}")

# --- å‡ºå›¾ä¸è¡¨æ ¼ ---
if has_df and x_col and y_cols:
    grouped = aggregate(df, x_col, y_cols, agg, time_gran)

    if grouped.empty:
        st.warning("æ²¡æœ‰å¯èšåˆçš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ X/Y/èšåˆæ–¹å¼ã€‚")
    else:
        # X èŒƒå›´æ»‘æ¡ï¼ˆä»…å½“ X ä¸ºæ•°å€¼æˆ–æ•´æ•°ï¼‰
        if pd.api.types.is_numeric_dtype(grouped["X"]):
            xmin, xmax = int(grouped["X"].min()), int(grouped["X"].max())
            lo, hi = st.sidebar.slider("X èŒƒå›´", min_value=xmin, max_value=xmax, value=(xmin, xmax))
            grouped = grouped[(grouped["X"] >= lo) & (grouped["X"] <= hi)]

        # ç”»å›¾
        st.subheader(f"æŒ‰ã€Œ{x_col}ã€èšåˆï¼ˆ{agg}ï¼‰", divider=True)
        fig = px.bar(grouped, x="X", y=y_cols[0], title="", labels={"X": "X"})
        # è¿½åŠ å…¶ä½™ y ä½œä¸ºå åŠ æŸ±
        for c in y_cols[1:]:
            fig.add_bar(x=grouped["X"], y=grouped[c], name=c)
        # é«˜äº®æœ€å¤§å€¼æ‰€åœ¨ x
        try:
            max_idx = grouped[y_cols[0]].idxmax()
            max_x = grouped.loc[max_idx, "X"]
            fig.add_vline(x=max_x, line_color="tomato", line_width=2, opacity=0.6)
        except Exception:
            pass
        st.plotly_chart(fig, use_container_width=True)

        # å½“å‰èšåˆè§†å›¾
        st.subheader("å½“å‰èšåˆè§†å›¾ï¼ˆå¯ä¸‹è½½ï¼‰", divider=True)
        st.dataframe(grouped, use_container_width=True, height=380)
        st.download_button(
            "ä¸‹è½½å½“å‰èšåˆ CSV",
            grouped.to_csv(index=False).encode("utf-8-sig"),
            file_name="aggregated_view.csv",
            mime="text/csv",
            use_container_width=True,
        )

        # åŸå§‹æ•°æ®é¢„è§ˆ
        with st.expander("åŸå§‹æ•°æ®é¢„è§ˆï¼ˆå‰ 200 è¡Œï¼‰"):
            st.dataframe(df.head(200), use_container_width=True)

else:
    # æ²¡æœ‰è¶³å¤Ÿæ¡ä»¶æ—¶çš„å‹å¥½æç¤º
    st.info("ğŸ‘‰ è¯·åœ¨å·¦ä¾§è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨ªåæ ‡ (X) ä¸ä¸€ä¸ªæ•°å€¼åˆ— (Y) ï¼Œå†æŸ¥çœ‹å›¾è¡¨ã€‚")
